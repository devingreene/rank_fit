{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning!  This needs to be updated.  There is precedent for a lot of these ideas, and I am no longer that enthused about the Bayesian interpretation.\n",
    "\n",
    "We propose methods for attributing numerical rank scores to a set of contestants, based on a matrix consisting of the outcomes, win or lose, of a series of contests in which the contestents participate.  \n",
    "\n",
    "## Maximum Likelihood Approach\n",
    "\n",
    "Our first approach is a maximum likelihood approach.  Define the matrix $a_{ij}$ as follows:\n",
    "\n",
    "$$a_{ij} = \\text{# of contests between i and j where i won}$$\n",
    "\n",
    "Since only relative rating is meaningful, we subject the ranking parameters $\\lambda_1, \\lambda_2, \\cdots, \\lambda_n$ of the $n$ contestants to the constraint that the mean is zero:\n",
    "\n",
    "$$\\sum_i\\, \\lambda_i = 0$$\n",
    "\n",
    "The values of the $\\lambda$s are then those which maximize the following objective function:\n",
    "\n",
    "[1] $$\\sum_{ij}\\, a_{ij}\\log \\mathrm{erf}\\left(\\frac{\\lambda_i - \\lambda_j}{\\sqrt{2}}\\right)$$\n",
    "\n",
    "where $\\mathrm{erf}(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x \\, \\exp\\left( \\frac{-t^2}{2}\\right) \\, dt$.\n",
    "\n",
    "What follows is a discussion of the intuition behind [1].  We imagine\n",
    "that the result of each contest between player $i$ and $j$ is\n",
    "determined by drawing two numbers, both Gaussian distributions with\n",
    "standard deviation one and means $\\lambda_i$ and $\\lambda_j$.  The\n",
    "player with the higher score wins.  Let $X_i$ be the $X_j$ numbers\n",
    "drawn: The difference $X_i - X_j$ is a random variable such that \n",
    "\n",
    "$$X_i - X_j \\sim \\mathcal{N}(\\lambda_i - \\lambda_j,\\sqrt{2})$$\n",
    "\n",
    "The matrix being the result of a set of contests, the probability of\n",
    "the outcome is \n",
    "\n",
    "$$\\prod_{ij} \\mathrm{erf}\\left(\\frac{\\lambda_i -\\lambda_j}{\\sqrt{2}}\\right)^{a_{ij}}$$\n",
    "\n",
    "and taking logs gives [1].\n",
    "\n",
    "## Bayesian Approach\n",
    "\n",
    "An alternative approach is to add a penalty to the objective function consisting of the square\n",
    "of the $L^2$ norm of the ranking paramters, scaled by a parameter.\n",
    "\n",
    "[2] $$\\sum_{ij}\\, a_{ij}\\log\\, \\mathrm{erf}\\left(\\frac{\\lambda_i -\n",
    "\\lambda_j}{\\sqrt{2}}\\right) - \\alpha\\sum_{i=1}^n\\, \\lambda_i^2$$\n",
    "\n",
    "Again, the solution is subject to the constraint $\\sum_{i=1}^n\\, \\lambda_i = 0$.\n",
    "\n",
    "Note that [2] reduces to [1] when $\\alpha = 0$.  This approach introduces a certain amount of \"inertia\" in the development of the rankings.  For instance, an intrinsically superior player will be required to prove itself through several victorious contests before its ranking is sufficiently adjusted to reflect its skill level.  The primary motivation for including the penalty term is to prevent the convergence problems that arise when maximizing [1].  To take a simple example, in a series of games in which one player is undefeated, optimizing [1] will result in that player having an infinite numerical rank.  By introducing the penalty term, we prevent non-convergence of player's scores in certain singular cases.  \n",
    "\n",
    "We note that there is a Baysian interpretation of the formulation above.  The prior distribution of players' scores is given by the density function \n",
    "\n",
    "$$\\text{Const}\\cdot \\exp\\left(-\\alpha\\sum_{i=1}^n\\, \\lambda_i^2\\right).$$\n",
    "\n",
    "After the contests enumerated by $(a_{ij})$ are completed, the posterior distribution has density function\n",
    "\n",
    "$$\\text{Const}\\cdot \\prod_{ij} \\mathrm{erf}\\left(\\frac{\\lambda_i - \\lambda_j}{\\sqrt{2}}\\right)^{a_{ij}}\\cdot \\exp\\left(-\\alpha\\sum_{i=1}^n\\, \\lambda_i^2\\right)$$\n",
    "\n",
    "which becomes [2] after taking logs.  We then consider the player scores which maximize the posterior density function to be the correct ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
